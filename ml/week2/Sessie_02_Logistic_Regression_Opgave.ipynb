{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opdracht classificatie 1 - logistic regression\n",
    "\n",
    "Logistische regressie is een bijzonder populaire classificatietechniek. Enerzijds door zijn eenvoud en relatief lage eisen die het stelt in termen van rekenkracht. In veel gevallen is de performantie qua accuracy vergelijkbaar (en soms beter) dan gecompliceerdere algoritmes zoals de support vector machines.\n",
    "Daarnaast heeft logistische regressie het voordeel dat het getrainde model een voorspelling doet in termen van de kans dat de input tot een bepaalde klasse behoort. Uit deze kans kan je afleiden hoe overtuigd het model is van de gemaakte voorspelling.\n",
    "\n",
    "Het is de bedoeling om via enkele classificatieopdrachten inzicht te verkrijgen in:\n",
    "- Correct trainen en het uitvoeren van hyperparameter tuning bij logistische regressie.\n",
    "- Classificaties kunnen uitvoeren via logistische regressie.\n",
    "- Feature engineering uitvoeren.\n",
    "- Interpreteren van de verschillende performance metrics: accuracy, recall, precision, f1-score, ROC.\n",
    "- Kunnen omgaan met niet-gebalanceerde data en het kunnen regelen tussen het aantal false positives en false negatives. \n",
    "- Weten wanneer je te maken hebt met overfitting en underfitting en de juiste bijstellingen kunnen doen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opdracht 1: Classificatie van wijn\n",
    "\n",
    "Het doel van deze classificatie is te kunnen achterhalen op basis van chemische parameters van welke wijnboer (cultivar) een wijn afkomstig is.\n",
    "\n",
    "Gebruik hiervoor de dataset *wine_data.csv*. De features bevinden zich in de eerste kolommen van de dataset. De targets/outputs zijn in de laatste kolom te vinden.\n",
    "\n",
    "### Inlezen van de dataset en vooranalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs Alcohol</th>\n",
       "      <th>MalicAcid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>AlcalinityOfAsh</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>TotalPhenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>NonflavanoidsPhenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>ColorIntensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Cultivar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.08</td>\n",
       "      <td>1.33</td>\n",
       "      <td>2.30</td>\n",
       "      <td>23.6</td>\n",
       "      <td>70</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.07</td>\n",
       "      <td>3.21</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.08</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.51</td>\n",
       "      <td>24.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.40</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2.72</td>\n",
       "      <td>630</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.37</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1.92</td>\n",
       "      <td>19.6</td>\n",
       "      <td>78</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.04</td>\n",
       "      <td>4.68</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.48</td>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.11</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.70</td>\n",
       "      <td>15.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.28</td>\n",
       "      <td>5.30</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.18</td>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.04</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2.38</td>\n",
       "      <td>22.0</td>\n",
       "      <td>80</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2.57</td>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.25</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.12</td>\n",
       "      <td>19.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.63</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.17</td>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.69</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.7</td>\n",
       "      <td>80</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.06</td>\n",
       "      <td>495</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.77</td>\n",
       "      <td>3.43</td>\n",
       "      <td>1.98</td>\n",
       "      <td>16.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.12</td>\n",
       "      <td>372</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.88</td>\n",
       "      <td>5.04</td>\n",
       "      <td>2.23</td>\n",
       "      <td>20.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.68</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.33</td>\n",
       "      <td>415</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.08</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.32</td>\n",
       "      <td>18.5</td>\n",
       "      <td>81</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.27</td>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inputs Alcohol  MalicAcid   Ash  AlcalinityOfAsh  Magnesium  TotalPhenols  \\\n",
       "0           12.08       1.33  2.30             23.6         70          2.20   \n",
       "1           12.08       1.13  2.51             24.0         78          2.00   \n",
       "2           12.37       1.17  1.92             19.6         78          2.11   \n",
       "3           13.11       1.01  1.70             15.0         78          2.98   \n",
       "4           12.04       4.30  2.38             22.0         80          2.10   \n",
       "5           12.25       1.73  2.12             19.0         80          1.65   \n",
       "6           12.69       1.53  2.26             20.7         80          1.38   \n",
       "7           12.77       3.43  1.98             16.0         80          1.63   \n",
       "8           13.88       5.04  2.23             20.0         80          0.98   \n",
       "9           12.08       1.83  2.32             18.5         81          1.60   \n",
       "\n",
       "   flavanoids  NonflavanoidsPhenols  Proanthocyanins  ColorIntensity   Hue  \\\n",
       "0        1.59                  0.42             1.38            1.74  1.07   \n",
       "1        1.58                  0.40             1.40            2.20  1.31   \n",
       "2        2.00                  0.27             1.04            4.68  1.12   \n",
       "3        3.18                  0.26             2.28            5.30  1.12   \n",
       "4        1.75                  0.42             1.35            2.60  0.79   \n",
       "5        2.03                  0.37             1.63            3.40  1.00   \n",
       "6        1.46                  0.58             1.62            3.05  0.96   \n",
       "7        1.25                  0.43             0.83            3.40  0.70   \n",
       "8        0.34                  0.40             0.68            4.90  0.58   \n",
       "9        1.50                  0.52             1.64            2.40  1.08   \n",
       "\n",
       "   OD280/OD315  Proline  Cultivar  \n",
       "0         3.21      625         1  \n",
       "1         2.72      630         1  \n",
       "2         3.48      510         1  \n",
       "3         3.18      502         1  \n",
       "4         2.57      580         1  \n",
       "5         3.17      510         1  \n",
       "6         2.06      495         1  \n",
       "7         2.12      372         1  \n",
       "8         1.33      415         2  \n",
       "9         2.27      480         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inlezen van de data\n",
    "dataset = pd.read_csv('wine_data.csv')\n",
    "dataset.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bepaal het aantal klasses. Met andere woorden, hoeveel verschillende wijnboeren zijn er? Is de dataset gebalanceerd? Een gebalanceere dataset is een dataset waar de verschillende klasses gelijkmatig voorkomen. Bij niet-gebalanceerde data kan het classificatiemodel een voorkeur krijgen voor de meerderheidsklasse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aantal klasses en gebalanceerdheid controleren\n",
    "klasses = dataset.Cultivar.unique()\n",
    "print(klasses)\n",
    "len(klasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          inputs Alcohol  MalicAcid  Ash  AlcalinityOfAsh  Magnesium  \\\n",
      "Cultivar                                                               \n",
      "0                     59         59   59               59         59   \n",
      "1                     71         71   71               71         71   \n",
      "2                     48         48   48               48         48   \n",
      "\n",
      "          TotalPhenols  flavanoids  NonflavanoidsPhenols  Proanthocyanins  \\\n",
      "Cultivar                                                                    \n",
      "0                   59          59                    59               59   \n",
      "1                   71          71                    71               71   \n",
      "2                   48          48                    48               48   \n",
      "\n",
      "          ColorIntensity  Hue  OD280/OD315  Proline  \n",
      "Cultivar                                             \n",
      "0                     59   59           59       59  \n",
      "1                     71   71           71       71  \n",
      "2                     48   48           48       48  \n"
     ]
    }
   ],
   "source": [
    "g = dataset.groupby('Cultivar').count()\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7facf58eaa30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Cultivar', data=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bepaal de statistische kerngetallen van de verschillende features en targets. Gebruik hiervoor de *describe* functie (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html). Gebruik de resultaten om na te gaan of er mogelijks ontbrekende waarden, uitschieters of onrealistische waarden zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs Alcohol</th>\n",
       "      <th>MalicAcid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>AlcalinityOfAsh</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>TotalPhenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>NonflavanoidsPhenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>ColorIntensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Cultivar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "      <td>0.938202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "      <td>0.775035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       inputs Alcohol   MalicAcid         Ash  AlcalinityOfAsh   Magnesium  \\\n",
       "count      178.000000  178.000000  178.000000       178.000000  178.000000   \n",
       "mean        13.000618    2.336348    2.366517        19.494944   99.741573   \n",
       "std          0.811827    1.117146    0.274344         3.339564   14.282484   \n",
       "min         11.030000    0.740000    1.360000        10.600000   70.000000   \n",
       "25%         12.362500    1.602500    2.210000        17.200000   88.000000   \n",
       "50%         13.050000    1.865000    2.360000        19.500000   98.000000   \n",
       "75%         13.677500    3.082500    2.557500        21.500000  107.000000   \n",
       "max         14.830000    5.800000    3.230000        30.000000  162.000000   \n",
       "\n",
       "       TotalPhenols  flavanoids  NonflavanoidsPhenols  Proanthocyanins  \\\n",
       "count    178.000000  178.000000            178.000000       178.000000   \n",
       "mean       2.295112    2.029270              0.361854         1.590899   \n",
       "std        0.625851    0.998859              0.124453         0.572359   \n",
       "min        0.980000    0.340000              0.130000         0.410000   \n",
       "25%        1.742500    1.205000              0.270000         1.250000   \n",
       "50%        2.355000    2.135000              0.340000         1.555000   \n",
       "75%        2.800000    2.875000              0.437500         1.950000   \n",
       "max        3.880000    5.080000              0.660000         3.580000   \n",
       "\n",
       "       ColorIntensity         Hue  OD280/OD315      Proline    Cultivar  \n",
       "count      178.000000  178.000000   178.000000   178.000000  178.000000  \n",
       "mean         5.058090    0.957449     2.611685   746.893258    0.938202  \n",
       "std          2.318286    0.228572     0.709990   314.907474    0.775035  \n",
       "min          1.280000    0.480000     1.270000   278.000000    0.000000  \n",
       "25%          3.220000    0.782500     1.937500   500.500000    0.000000  \n",
       "50%          4.690000    0.965000     2.780000   673.500000    1.000000  \n",
       "75%          6.200000    1.120000     3.170000   985.000000    2.000000  \n",
       "max         13.000000    1.710000     4.000000  1680.000000    2.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistische vooranalyse\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   inputs Alcohol        178 non-null    float64\n",
      " 1   MalicAcid             178 non-null    float64\n",
      " 2   Ash                   178 non-null    float64\n",
      " 3   AlcalinityOfAsh       178 non-null    float64\n",
      " 4   Magnesium             178 non-null    int64  \n",
      " 5   TotalPhenols          178 non-null    float64\n",
      " 6   flavanoids            178 non-null    float64\n",
      " 7   NonflavanoidsPhenols  178 non-null    float64\n",
      " 8   Proanthocyanins       178 non-null    float64\n",
      " 9   ColorIntensity        178 non-null    float64\n",
      " 10  Hue                   178 non-null    float64\n",
      " 11  OD280/OD315           178 non-null    float64\n",
      " 12  Proline               178 non-null    int64  \n",
      " 13  Cultivar              178 non-null    int64  \n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 19.6 KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing en opsplitsen van de dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits de dataset in **features en targets**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178,) (178, 13)\n"
     ]
    }
   ],
   "source": [
    "# opsplitsen in features en targets\n",
    "y = dataset['Cultivar'].values\n",
    "X = dataset.drop(['Cultivar'], axis=1).values\n",
    "\n",
    "print(y.shape, X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creëer een **trainingset en een testset**. Zorg dat je 70 wijnen in de test set zitten hebt. Gebruik hiervoor train_test_split functie. Meer info is te vinden op http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aanmaken van een training set en test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=70, random_state=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normaliseer de dataset**. Zorg er dus voor dat de features op een gelijke schaalverdeling staan. Voor het normaliseren kan gebruik gemaakt worden van de *preprocessing.StandardScaler()*. Meer info over het gebruik ervan is te vinden op http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normaliseren\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainen van een logistic regression classifier en testen van het bekomen model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train een logistic regression classifier (http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) op de training data. \n",
    "Kies C=1 als startwaarde. \n",
    "\n",
    "Test het getrainde model op de test set. Bepaal hierbij de confusion matrix, de accuracy en het classification report. Wat zijn de bevindingen?\n",
    "\n",
    "Probeer de performantie van het model te verhogen door het uitvoeren van hyperparameter tuning. Mogelijke hyperparameters zijn:\n",
    "- Aanpassen van de waarde van C \n",
    "- Kiezen van een andere solver\n",
    "- Regularisatie (penalty) toepassen via L1 of L2 \n",
    "- Toevoegen van extra (polynomial) features \n",
    "- Indien je te maken hebt met niet-gebalanceerde data, dan kan je de class_weigt='balanced' parameter meegeven. Verklaar het effect ervan op de accuracy, recall, precision en de f1-score.\n",
    "\n",
    "\n",
    "Schrijf de conclusies neer. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  0  0]\n",
      " [ 0 29  1]\n",
      " [ 0  0 18]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        22\n",
      "           1       1.00      0.97      0.98        30\n",
      "           2       0.95      1.00      0.97        18\n",
      "\n",
      "    accuracy                           0.99        70\n",
      "   macro avg       0.98      0.99      0.99        70\n",
      "weighted avg       0.99      0.99      0.99        70\n",
      "\n",
      "\n",
      "\n",
      "0.9857142857142858\n"
     ]
    }
   ],
   "source": [
    "# trainen van het model en hyperparameter tuning +  conclusies\n",
    "logreg = linear_model.LogisticRegression(C=0.44, solver='liblinear')\n",
    "model = logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "\n",
    "cs = np.logspace(-2, 6, 1000)\n",
    "\n",
    "for c in cs:\n",
    "    logreg = linear_model.LogisticRegression(C=c, solver='liblinear')\n",
    "    logreg.fit(X_train,y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    test_acc.append(accuracy_score(y_test, y_pred))\n",
    "    train_acc.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Plot r2\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.semilogx(cs, train_acc, label='Train')\n",
    "plt.semilogx(cs, test_acc, label='Test')\n",
    "plt.legend(loc='lower left')\n",
    "plt.ylim([0, 1.2])\n",
    "plt.xlabel('Regularization parameter')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4463233926710395"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_acc)\n",
    "cs[test_acc.index(max(test_acc))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voorspel aan de hand van het getrainde model\n",
    "\n",
    "Voorspel van welke wijnboer een wijn afkomstig is met volgende samenstelling:\n",
    "\n",
    "inputs Alcohol: 13.52 - \n",
    "MalicAcid: 2.05 - \n",
    "Ash: 2.20 - \n",
    "AlcalinityOfAsh: 17.3 - \n",
    "Magnesium: 120 - \n",
    "TotalPhenols: 2.60 - \n",
    "flavanoids: 3.52 - \n",
    "NonflavanoidsPhenols: 0.30 - \n",
    "Proanthocyanins: 2.28 - \n",
    "ColorIntensity: 7.80 - \n",
    "Hue: 0.77 - \n",
    "OD280/OD315: 2.90 - \n",
    "Proline: 862\n",
    "\n",
    "\n",
    "Geef ook de overtuiging van het model weer dat de wijn van die bepaalde wijnboer afkomstig is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[[9.99966174e-01 1.22841766e-07 3.37033995e-05]]\n"
     ]
    }
   ],
   "source": [
    "# predictie\n",
    "wine = [[13.52, 2.05, 2.20, 17.3, 120, 2.60, 3.52, 0.30, 2.28, 7.80, 0.77, 2.90, 862]]\n",
    "\n",
    "# scaler\n",
    "wine = scaler.transform(wine)\n",
    "# predict \n",
    "pred = logreg.predict(wine)\n",
    "print(pred)\n",
    "#probs predict\n",
    "classification = logreg.predict_proba(wine)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vraag de coëfficiënten van het model op via '.coef_'. Verklaar waarom het aantal coëfficiënten een veelvoud is van het aantal features. Welke features spelen een belangrijke rol om te bepalen of een wijn al dan niet van wijnboer 1 afkomstig is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.04467752,  0.16456627,  0.64505689, -0.90826653, -0.03911357,\n",
       "         0.2924864 ,  0.50308355, -0.17845017, -0.14241879, -0.02204284,\n",
       "         0.24082192,  0.62602893,  1.30750262],\n",
       "       [-1.28055731, -0.69285711, -0.79797774,  0.56538891, -0.08171916,\n",
       "         0.07130323,  0.23972581,  0.09713692,  0.32220602, -0.97949127,\n",
       "         0.52100215,  0.02752276, -1.14285372],\n",
       "       [ 0.38419114,  0.62315039,  0.23295089,  0.21338276,  0.03408266,\n",
       "        -0.3640689 , -0.73692394,  0.10825322, -0.19605863,  1.02279427,\n",
       "        -0.74641789, -0.64168372, -0.12533263]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coëfficiënten interpreteren \n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusie\n",
    "Omdat er X aantal verschillende klasses zijn.\n",
    "Het alcohol percentage speelt een belangrijke rol in de klassificatie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opdracht 2: Diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het bestand *diabetes.csv* bevat medische gegevens van meer dan 300 personen waarbij telkens geweten is of de persoon al dan niet diabetes heeft.\n",
    "Train nu een logic regression model dat op basis van de features een zo goed mogelijke predictie kan doen of iemand al dan niet diabetes heeft.\n",
    "\n",
    "### Inlezen van de dataset en vooranalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inlezen van de dataset\n",
    "dataset = pd.read_csv('diabetes.csv')\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controleer of de dataset inconsistenties of foute waarden bevat. Gebruik listwise deletion. Dit betekent dat je alle gegevens van een persoon uit de dataset verwijdert van zodra er 1 feature foutief is of ontbreekt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inconsistenties opsporen\n",
    "dataset[['Glucose', 'BloodPressure', 'SkinThickness', 'BMI', 'Insulin']] = dataset[['Glucose', 'BloodPressure', 'SkinThickness', 'BMI', 'Insulin']].replace(0, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace=True)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bepaal de verdeling van het aantal personen met diabetes ten opzichte van het aantal personen zonder. Is de dataset gebalanceerd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gebalanceerdheid controleren\n",
    "sns.countplot(x='Outcome', data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De dataset is niet gebalanceerd, er zijn veer meer gevallen waarbij er geen diabetes is vast gesteld."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bepaal de statistische kerngetallen van de verschillende features en target. Gebruik hiervoor de *describe* functie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistische kerngetallen\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(dataset.corr(), annot=True, square=True, \n",
    "            mask=np.zeros_like(dataset.corr(), dtype=np.bool), ax=ax,\n",
    "           cmap=sns.diverging_palette(220, 10, as_cmap=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing en opsplitsen van de dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits de dataset in **features en targets**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen in features en targets\n",
    "y = dataset.Outcome.values\n",
    "X = dataset.drop(['Outcome'], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creëer een **trainingset en een testset**. Zorg dat er 100 patiënten in de testset steken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set en test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100, random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normaliseer de dataset**. Zorg er dus voor dat de features op een gelijke schaalverdeling staan. Voor het normaliseren kan gebruik gemaakt worden van de *preprocessing.StandardScaler()*. Meer info over het gebruik ervan is te vinden op http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisatie\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainen van een logistic regression classifier en testen van het bekomen model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train een logistic regression classifier op de training data. Kies C=1 als startwaarde. Mocht de dataset niet gebalanceerd zijn (de ene klasse komt frequenter voor dan de andere klasse) dan kan je bij de creatie van het logistic regression model de parameter class_weight='balanced' meegeven. Meer info: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "Test het getrainde model op de test set. Bepaal hierbij de confusion matrix, de accuracy en het classification report. Wat zijn de bevindingen? Probeer ook verschillende solvers uit. Bepaal ook telkens de ROC en formuleer conclusies.\n",
    "\n",
    "Probeer de performantie van de classifier te verhogen door de parameter C te veranderen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "log_reg = linear_model.LogisticRegression(C=0.01, class_weight='balanced', solver='liblinear')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bevindingen\n",
    "De accuracy is met 73% vrij oke.\n",
    "De F1 score van de niet diabetes patienten ligt hoger doordat de train data meer voorbeelden bevat waarbij de patient geen diabetes heeft.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "\n",
    "cs = np.logspace(-2, 6, 1000)\n",
    "\n",
    "for c in cs:\n",
    "    logreg = linear_model.LogisticRegression(C=c, solver='liblinear')\n",
    "    logreg.fit(X_train,y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    test_acc.append(accuracy_score(y_test, y_pred))\n",
    "    train_acc.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Plot r2\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.semilogx(cs, train_acc, label='Train')\n",
    "plt.semilogx(cs, test_acc, label='Test')\n",
    "plt.legend(loc='lower left')\n",
    "plt.ylim([0, 1.2])\n",
    "plt.xlabel('Regularization parameter')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "Creeër hogere orde features door gebruik te maken van *preprocessing.PolynomialFeatures*. Meer info is te vinden op http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
    "\n",
    "Deze functie zal automatische hogere orde features aanmaken door het combineren van de aanwezige features. Heb je bijvoorbeeld drie features, zijnde A, B en C dan worden bij de keuze van een derde orde PolynomialFeatures volgende nieuwe features bijgemaakt:\n",
    "$A^3, B^3,C^3,A^2B,A^2C,AB^2, B^2C,...$\n",
    "\n",
    "Experimenteer met verschillende ordes en gebruik de regularisatieparameter C om de performantie te verhogen. Voor indien nodig ook regularisatie uit via een L1 of L2 penalty.\n",
    "\n",
    "**Opgepast**: het kiezen van een te hoge orde zorgt voor een exponentiële toename aan features waardoor de logistic regression classifier niet meer binnen aanvaardbare tijd getraind kan worden. Advies is om niet hoger te gaan dan 4de orde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "\n",
    "cs = np.logspace(-2, 6, 1000)\n",
    "\n",
    "graad = 2\n",
    "poly = PolynomialFeatures(graad)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = poly.transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "for c in cs:\n",
    "    logreg = linear_model.RidgeClassifier(alpha=c,tol=0.0001,fit_intercept=True, class_weight='balanced')\n",
    "    logreg.fit(X_train_poly,y_train)\n",
    "    y_pred = logreg.predict(X_test_poly)\n",
    "    test_acc.append(accuracy_score(y_test, y_pred))\n",
    "    train_acc.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Plot r2\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.semilogx(cs, train_acc, label='Train')\n",
    "plt.semilogx(cs, test_acc, label='Test')\n",
    "plt.legend(loc='lower left')\n",
    "plt.ylim([0, 1.2])\n",
    "plt.xlabel('Regularization parameter')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "cs[test_acc.index(max(test_acc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L2\n",
    "lregmodel_poly = linear_model.RidgeClassifier(alpha=0.48048704396551317,tol=0.0001,fit_intercept=True, class_weight='balanced')\n",
    "lregmodel_poly.fit(X_train_poly,y_train)\n",
    "\n",
    "y_pred = lregmodel_poly.predict(X_test_poly)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wat zijn de bevindingen? Formuleer een conclusie. Bespreek hierin de performantie van de getrainde modellen. Wat is de invloed van de parameter C en van het aantal features? Heb je te maken gehad met underfitting en overfitting en hoe heb je dit bepaald? Welke accuracy werd bekomen en hoe zit het met de Recall en Precision? Is de grootte van de trainingset voldoende?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antwoord: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voorspel aan de hand van het getrainde model\n",
    "\n",
    "Voorspel of iemand met onderstaande medische parameters als dan niet diabetes heeft. Geef ook de zekerheid van het model weer (kansen dat de patiënt tot een bepaalde klasse behoort).\n",
    "\n",
    "Pregnancies: 2 -\n",
    "Glucose: 132 -\n",
    "BloodPressure: 74 - \n",
    "SkinThickness: 20 - \n",
    "Insulin: 21 - \n",
    "BMI: 24.3 - \n",
    "DiabetesPedigreeFunction: 128 - \n",
    "Age: 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voorspelling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standaard zal het model een sample toewijzen aan klasse 1 van zodra de probiliteit boven de threshold van 50% uisteekt. \n",
    "Men wil echter de kans op false negatives drastisch verminderen door het aanpassen van de threshold. Welke threshold moet men instellen om ervoor te zorgen dat het model op de test set geen false negatives meer voorspelt en toch nog een zo hoog mogelijke accuraatheid heeft?\n",
    "Stel het aantal false negatives in functie van de threshold grafisch voor. Bespreek de resultaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduceren van het aantal false negatives door de threshold aan te passen\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opdracht 3. Human resources\n",
    "\n",
    "Een groot bedrijf probeert te voorspellen of een werknemer binnenkort al dan niet het bedrijf zal verlaten en hoopt zo tijdig te kunnen ingrijpen.\n",
    "Gebruik logistische regressie op de dataset 'Human_Resources.csv' om een zo accuraat mogelijk model te trainen. \n",
    "Tevens wil het bedrijf vooral false negatives vermijden.\n",
    "Welke zijn de top 3 features die het sterkst bepalen of een werknemer het bedrijf zal verlaten?\n",
    "\n",
    "De dataset bestaat uit de volgende features:\n",
    "\n",
    "- satisfaction_level: mate van voldoening op het werk.\n",
    "- last_evaluationTime: aantal jaar sinds de laatste evaluatie.\n",
    "- number_project: het aantal projecten die de werknemer op het bedrijf heeft afgewerkt.\n",
    "- average_montly_hours: het aantal uur die de werknemer gemiddeld per maand aanwezig is op de werkplaats.\n",
    "- time_spend_company: het aantal jaar in dienst van het bedrijf.\n",
    "- work_accident: of de werknemer al een werkongeval heeft gehad.\n",
    "- promotion_last_5years: of de werknemer al dan niet een promotie heeft gehad de afgelopen 5 jaar.\n",
    "- department: het departement waar de werknemer voor werkt.\n",
    "- salary: relatief loon (low, medium, high).\n",
    "\n",
    "De te voorspellen target = left: of de werknemer het bedrijf al dan niet heeft verlaten (0 of 1)\n",
    "\n",
    "Gebruik one-hot encoding om categorische features om te zetten naar one-hot features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Human_Resources.csv')\n",
    "print('Dimensie van de dataset:',dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uitwerking opdracht human resources\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
