{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re #regular expressions\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "pd.set_option('display.max_rows',1000)\n",
    "pd.set_option('display.max_columns',1000)\n",
    "pd.set_option('display.max_colwidth',150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wif my family booking tour package.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>ham</td>\n",
       "      <td>GRAN ONLYFOUND OUT AFEW DAYS AGO.CUSOON HONI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>ham</td>\n",
       "      <td>7 wonders in My WORLD 7th You 6th Ur style 5th Ur smile 4th Ur Personality 3rd Ur Nature 2nd Ur SMS and 1st Ur Lovely Friendship... good morning dear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>spam</td>\n",
       "      <td>FREE for 1st week! No1 Nokia tone 4 ur mobile every week just txt NOKIA to 8077 Get txting and tell ur mates. www.getzed.co.uk POBox 36504 W45WQ 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>ham</td>\n",
       "      <td>Let me know how it changes in the next 6hrs. It can even be appendix but you are out of that age range. However its not impossible. So just chill ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call you  later. I am in meeting sir.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>ham</td>\n",
       "      <td>Im in inperialmusic listening2the weirdest track ever by”leafcutter john”-sounds like insects being molested&amp;someone plumbing,remixed by evil men ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>ham</td>\n",
       "      <td>Dare i ask... Any luck with sorting out the car?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>ham</td>\n",
       "      <td>My birthday is on feb  #  da. .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>ham</td>\n",
       "      <td>Thk shld b can... Ya, i wana go 4 lessons... Haha, can go for one whole stretch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aight, sounds good. When do you want me to come down?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nope. I just forgot. Will show next week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>ham</td>\n",
       "      <td>Detroit. The home of snow. Enjoy it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes..gauti and sehwag out of odi series.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes :)it completely in out of form:)clark also utter waste.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>ham</td>\n",
       "      <td>You're not sure that I'm not trying to make xavier smoke because I don't want to smoke after being told I smoke too much?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hey cutie. How goes it? Here in WALES its kinda ok. There is like hills but i still avent killed myself.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hey gals.. Anyone of u going down to e driving centre tmr?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>ham</td>\n",
       "      <td>Or remind me in a few hrs.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     type  \\\n",
       "830   ham   \n",
       "831   ham   \n",
       "832   ham   \n",
       "833  spam   \n",
       "834   ham   \n",
       "835   ham   \n",
       "836   ham   \n",
       "837   ham   \n",
       "838   ham   \n",
       "839   ham   \n",
       "840   ham   \n",
       "841   ham   \n",
       "842   ham   \n",
       "843   ham   \n",
       "844   ham   \n",
       "845   ham   \n",
       "846   ham   \n",
       "847   ham   \n",
       "848   ham   \n",
       "849   ham   \n",
       "\n",
       "                                                                                                                                                      text  \n",
       "830                                                                                                                    Wif my family booking tour package.  \n",
       "831                                                                                                           GRAN ONLYFOUND OUT AFEW DAYS AGO.CUSOON HONI  \n",
       "832  7 wonders in My WORLD 7th You 6th Ur style 5th Ur smile 4th Ur Personality 3rd Ur Nature 2nd Ur SMS and 1st Ur Lovely Friendship... good morning dear  \n",
       "833  FREE for 1st week! No1 Nokia tone 4 ur mobile every week just txt NOKIA to 8077 Get txting and tell ur mates. www.getzed.co.uk POBox 36504 W45WQ 1...  \n",
       "834  Let me know how it changes in the next 6hrs. It can even be appendix but you are out of that age range. However its not impossible. So just chill ...  \n",
       "835                                                                                                      Sorry, I'll call you  later. I am in meeting sir.  \n",
       "836  Im in inperialmusic listening2the weirdest track ever by”leafcutter john”-sounds like insects being molested&someone plumbing,remixed by evil men ...  \n",
       "837                                                                                                       Dare i ask... Any luck with sorting out the car?  \n",
       "838                                                                                                                        My birthday is on feb  #  da. .  \n",
       "839                                                                     Thk shld b can... Ya, i wana go 4 lessons... Haha, can go for one whole stretch...  \n",
       "840                                                                                                  Aight, sounds good. When do you want me to come down?  \n",
       "841                                                                                                               Nope. I just forgot. Will show next week  \n",
       "842                                                                                                                   Detroit. The home of snow. Enjoy it.  \n",
       "843                                                                                                                                                     Ok  \n",
       "844                                                                                                               Yes..gauti and sehwag out of odi series.  \n",
       "845                                                                                            Yes :)it completely in out of form:)clark also utter waste.  \n",
       "846                              You're not sure that I'm not trying to make xavier smoke because I don't want to smoke after being told I smoke too much?  \n",
       "847                                              Hey cutie. How goes it? Here in WALES its kinda ok. There is like hills but i still avent killed myself.   \n",
       "848                                                                                             Hey gals.. Anyone of u going down to e driving centre tmr?  \n",
       "849                                                                                                                             Or remind me in a few hrs.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importeer de dataset en splits op in features en targets\n",
    "\n",
    "# Inlezen dataset\n",
    "dataset = pd.read_csv('spam_train.csv')\n",
    "\n",
    "testset = pd.read_csv('spam_test.csv')\n",
    "\n",
    "# Opsplitsen in features en targets\n",
    "y_train = dataset.type.values\n",
    "X_train = dataset.text.values\n",
    "\n",
    "y_test = testset.type.values\n",
    "X_test = testset.text.values\n",
    "\n",
    "testset.tail(20)\n",
    "#print(X_train[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6b8c2469a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=dataset, x='type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "\n",
    "def text_preprocessing(text, language, minWordSize):\n",
    "    \n",
    "    # remove html\n",
    "    text_no_html = BeautifulSoup(str(text),\"html.parser\" ).get_text()\n",
    "    \n",
    "    # remove non-letters\n",
    "    text_alpha_chars = re.sub(\"[^a-zA-Z']\", \" \", str(text_no_html)) \n",
    "        \n",
    "    # convert to lower-case\n",
    "    text_lower = text_alpha_chars.lower()\n",
    "    \n",
    "    # remove stop words\n",
    "    stops = set(stopwords.words(language)) \n",
    "    text_no_stop_words = ' '\n",
    "    \n",
    "    for w in text_lower.split():\n",
    "        if w not in stops:  \n",
    "            text_no_stop_words = text_no_stop_words + w + ' '\n",
    "      \n",
    "       # do stemming\n",
    "    text_stemmer = ' '\n",
    "    stemmer = SnowballStemmer(language)\n",
    "    for w in text_no_stop_words.split():\n",
    "        text_stemmer = text_stemmer + stemmer.stem(w) + ' '\n",
    "         \n",
    "    # remove short words\n",
    "    text_no_short_words = ' '\n",
    "    for w in text_stemmer.split(): \n",
    "        if len(w) >=minWordSize:\n",
    "            text_no_short_words = text_no_short_words + w + ' '\n",
    " \n",
    "\n",
    "    return text_no_short_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training and test set to bag of words\n",
    "language = 'english'\n",
    "minWordLength = 2\n",
    "\n",
    "for i in range(X_train.size):\n",
    "    X_train[i] = text_preprocessing(X_train[i], language, minWordLength)\n",
    "    \n",
    "    \n",
    "for i in range(X_test.size):\n",
    "    X_test[i] = text_preprocessing(X_test[i], language, minWordLength)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sms ac jsco energi high may know channel day ur leadership skill strong psychic repli an question end repli end jsco \n"
     ]
    }
   ],
   "source": [
    "print(X_train[4707])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-071aac21776d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcount_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train_bag_of_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mX_train_bag_of_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX_test_bag_of_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \"\"\"\n\u001b[1;32m   1185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1217\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[1;32m   1220\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             raise ValueError(\"np.nan is an invalid document, expected byte or \"\n\u001b[0m\u001b[1;32m    219\u001b[0m                              \"unicode string.\")\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "# Make sparse features vectors \n",
    "# Bag of words\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_bag_of_words = count_vect.fit(X_train)\n",
    "X_train_bag_of_words = count_vect.transform(X_train)\n",
    "X_test_bag_of_words = count_vect.transform(X_test)\n",
    "\n",
    "print(X_train_bag_of_words)\n",
    "#print(X_test_bag_of_words)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_bag_of_words)\n",
    "X_train_tf = tf_transformer.transform(X_train_bag_of_words)\n",
    "X_test_tf = tf_transformer.transform(X_test_bag_of_words)\n",
    "print(X_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4709, 5742)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_bag_of_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       738\n",
      "        spam       0.99      0.84      0.91       112\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       850\n",
      "   macro avg       0.98      0.92      0.95       850\n",
      "weighted avg       0.98      0.98      0.98       850\n",
      "\n",
      "[[737   1]\n",
      " [ 18  94]]\n",
      "97.76470588235294\n"
     ]
    }
   ],
   "source": [
    "# Naive bayes\n",
    "\n",
    "NBclassifier = MultinomialNB(alpha=1)\n",
    "\n",
    "NBclassifier.fit(X_train_tf, y_train)\n",
    "\n",
    "y_pred = NBclassifier.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wouter/tensorflow/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression classifier\n",
    "lregclassifier = LogisticRegression(C=10)\n",
    "\n",
    "lregclassifier.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99       738\n",
      "        spam       0.99      0.92      0.95       112\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       850\n",
      "   macro avg       0.99      0.96      0.97       850\n",
      "weighted avg       0.99      0.99      0.99       850\n",
      "\n",
      "[[737   1]\n",
      " [  9 103]]\n",
      "98.82352941176471\n"
     ]
    }
   ],
   "source": [
    "# test logistic classifier\n",
    "\n",
    "y_pred = lregclassifier.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
