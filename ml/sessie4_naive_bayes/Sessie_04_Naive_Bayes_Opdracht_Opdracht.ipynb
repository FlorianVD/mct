{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opdracht Sessie 04 -  Natural Language Processing\n",
    "\n",
    "Sinds enkele jaren schieten de Natural Language Processing toepassingen als paddenstoelen uit de grond. EÃ©n van de belangrijkste redenen daarvoor is de steeds groter wordende beschikbaarheid van tekstuele data aangeleverd door bijvoorbeeld social media.\n",
    "\n",
    "In deze opdracht zal NLP toegepast worden in het kader van sentiment analysis. De bedoeling van sentiment analysis is om uit een tekstueel bericht zoals een email, sms, twitter bericht, Trip Advisor review het sentiment te voorspellen. Bedrijven weten bijvoorbeeld graag wat het sentiment is in de berichten die online over hen verschijnen.\n",
    "\n",
    "De opdracht bestaat uit 2 deelopdrachten.\n",
    "\n",
    "De eerste deelopdracht gaat rond het uitvoeren van pure sentiment analysis van Tweets.\n",
    "Bij de tweede deelopdracht is het de bedoeling om cyber trolls op te sporen.\n",
    "\n",
    "Telkens wordt het bag-of-words model gebruikt om tekst voor te stellen en vervolgens worden verschillende classifiers getraind om het sentiment/rating te voorspellen.\n",
    "\n",
    "Het bag-of-words model beschrijft het voorkomen van woorden binnen een document en doet dit op bais van een vocabulair van gekende woorden en meet de aanwezigheid van deze gekende woorden. De grote beperking van het bag-of-words model is dat het enkel rekening houdt met welke woorden in een bericht voorkomen en niet met de volgorde ervan. Daardoor is het bag-of-words model heel beperkt in het capteren van de context waarin woorden in een bericht voorkomen . Tijdens de module deep learning zullen we afstappen van het bag-of-words model en gebruik maken van word embeddings in combinatie met LSTM neurale netwerken. Op deze manier kunnen we modellen trainen die wel rekening houden met de context en woordvolgordes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "import re #regular expressions\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_rows',1000)\n",
    "pd.set_option('display.max_columns',1000)\n",
    "pd.set_option('display.max_colwidth',150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airline sentiment\n",
    "\n",
    "De dataset 'Airlines_sentiment.csv' bevat tweets over verschillende airlines. Jouw taak bestaat erin om een classifier te trainen die zo goed mogelijk het sentiment van de tweets kan classificeren als positive, neutral en negative.\n",
    "Het sentiment bevindt zich in de kolom 'airline_sentiment' en de tweet zelf in de kolom 'text'.\n",
    "Doorloop de volgende stappen:\n",
    "- Analyse van de data\n",
    "- Preprocessing\n",
    "- Training en hyperparameter tuning\n",
    "- Modeloptimalisatie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason:confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>681679794</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 19:46</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KristenReenders</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir thank you we got on a different flight to Chicago.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/22/15 12:01</td>\n",
       "      <td>5.695880e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>681679795</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 19:14</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>itsropes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flight. No warnings or communication until we were 15 minutes Late Flight. That's called shitty customer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/22/15 11:59</td>\n",
       "      <td>5.695870e+17</td>\n",
       "      <td>Texas</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>681679796</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 19:04</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sanyabun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to #BlackBerry10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/22/15 11:59</td>\n",
       "      <td>5.695870e+17</td>\n",
       "      <td>Nigeria,lagos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>681679797</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 18:59</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>0.6659</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SraJackson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir you have my money, you change my flight, and don't answer your phones! Any other suggestions so I can make my commitment??</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/22/15 11:59</td>\n",
       "      <td>5.695870e+17</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>681679798</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 19:06</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daviddtwu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know how many seats are on the next flight. Plz put us on standby for 4 people on the next flight?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/22/15 11:58</td>\n",
       "      <td>5.695870e+17</td>\n",
       "      <td>dallas, TX</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "14635  681679794    False   finalized                   3     2/25/15 19:46   \n",
       "14636  681679795    False   finalized                   3     2/25/15 19:14   \n",
       "14637  681679796    False   finalized                   3     2/25/15 19:04   \n",
       "14638  681679797    False   finalized                   3     2/25/15 18:59   \n",
       "14639  681679798    False   finalized                   3     2/25/15 19:06   \n",
       "\n",
       "      airline_sentiment  airline_sentiment:confidence          negativereason  \\\n",
       "14635          positive                        0.3487                     NaN   \n",
       "14636          negative                        1.0000  Customer Service Issue   \n",
       "14637           neutral                        1.0000                     NaN   \n",
       "14638          negative                        1.0000  Customer Service Issue   \n",
       "14639           neutral                        0.6771                     NaN   \n",
       "\n",
       "       negativereason:confidence   airline airline_sentiment_gold  \\\n",
       "14635                     0.0000  American                    NaN   \n",
       "14636                     1.0000  American                    NaN   \n",
       "14637                        NaN  American                    NaN   \n",
       "14638                     0.6659  American                    NaN   \n",
       "14639                     0.0000  American                    NaN   \n",
       "\n",
       "                  name negativereason_gold  retweet_count  \\\n",
       "14635  KristenReenders                 NaN              0   \n",
       "14636         itsropes                 NaN              0   \n",
       "14637         sanyabun                 NaN              0   \n",
       "14638       SraJackson                 NaN              0   \n",
       "14639        daviddtwu                 NaN              0   \n",
       "\n",
       "                                                                                                                                                        text  \\\n",
       "14635                                                                                        @AmericanAir thank you we got on a different flight to Chicago.   \n",
       "14636  @AmericanAir leaving over 20 minutes Late Flight. No warnings or communication until we were 15 minutes Late Flight. That's called shitty customer...   \n",
       "14637                                                                                           @AmericanAir Please bring American Airlines to #BlackBerry10   \n",
       "14638                @AmericanAir you have my money, you change my flight, and don't answer your phones! Any other suggestions so I can make my commitment??   \n",
       "14639             @AmericanAir we have 8 ppl so we need 2 know how many seats are on the next flight. Plz put us on standby for 4 people on the next flight?   \n",
       "\n",
       "      tweet_coord  tweet_created      tweet_id tweet_location  \\\n",
       "14635         NaN  2/22/15 12:01  5.695880e+17            NaN   \n",
       "14636         NaN  2/22/15 11:59  5.695870e+17          Texas   \n",
       "14637         NaN  2/22/15 11:59  5.695870e+17  Nigeria,lagos   \n",
       "14638         NaN  2/22/15 11:59  5.695870e+17     New Jersey   \n",
       "14639         NaN  2/22/15 11:58  5.695870e+17     dallas, TX   \n",
       "\n",
       "                    user_timezone  \n",
       "14635                         NaN  \n",
       "14636                         NaN  \n",
       "14637                         NaN  \n",
       "14638  Eastern Time (US & Canada)  \n",
       "14639                         NaN  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inlezen van de dataset\n",
    "\n",
    "dataset = pd.read_csv('Airline_sentiment.csv',encoding = 'ISO-8859-1')\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse van de dataset\n",
    "\n",
    "- Onderzoek de gebalanceerdheid van de dataset. Stel grafisch de verdeling voor van het sentiment.\n",
    "- Visualiseer de verdeling van het sentiment per airline. Maak daarvoor per airline een Seaborn countplot van het sentiment.\n",
    "- Welke airline lijkt op basis van deze tweet het best te scoren en welke het slechtst?\n",
    "- Uit hoeveel woorden bestaat het langste twitter bericht en uit hoeveel woorden het kortste?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7dffb38c10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyse van de dataset\n",
    "sns.countplot(data=dataset, x='airline_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f7dff6db130>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(y=\"airline\", col=\"airline_sentiment\", col_wrap=4,\n",
    "                data=dataset,\n",
    "                kind=\"count\", height=5, aspect=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virgin America -> positive: 152, negative: 181, rate -> 0.8397790055248618\n",
      "United -> positive: 492, negative: 2633, rate -> 0.1868590960881124\n",
      "Southwest -> positive: 570, negative: 1186, rate -> 0.4806070826306914\n",
      "Delta -> positive: 544, negative: 955, rate -> 0.5696335078534032\n",
      "US Airways -> positive: 269, negative: 2263, rate -> 0.11886875828546177\n",
      "American -> positive: 336, negative: 1960, rate -> 0.17142857142857143\n"
     ]
    }
   ],
   "source": [
    "# positivity rate per airline\n",
    "for airline in dataset.airline.unique():\n",
    "    # 0 -> negative\n",
    "    # 1 -> neutral\n",
    "    # 2 -> positive\n",
    "    airline_sentiments = dataset[dataset.airline == airline].groupby('airline_sentiment').count()['_unit_id'].unique()\n",
    "    positivity_rate = airline_sentiments[2] / airline_sentiments[0]\n",
    "    print(airline, f'-> positive: {airline_sentiments[2]}, negative: {airline_sentiments[0]}, rate ->', positivity_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max ->  229\n",
      "min ->  12\n"
     ]
    }
   ],
   "source": [
    "print('max -> ', dataset.text.map(len).max())\n",
    "print('min -> ', dataset.text.map(len).min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse\n",
    "De best scorende maatschappij is **Virgin America**. De verhouding tussen positieve en negatieve berichten is hier het best.\n",
    "De slechts scorende maatschappij is **US Airways**. De verhouding tussen positieve en negatieve berichten is hier het slechts. \n",
    "\n",
    "De langeste tweet is 229 karakters en de kortste is er 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Onderzoek of er mogelijks foutieve of ontbrekende data aanwezig is. \n",
    "Kuis de tweets op: verwijder stopwoorden en niet-letters, zet alles om naar lowercase en pas stemming toe.\n",
    "Maak gebruik van de CountVectorizer en TfidfTransformer om een bag-of-words model te creÃ«ren. \n",
    "\n",
    "Meer info: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer\n",
    "\n",
    "Splits op in een training set en test set. Zorg ervoor dat er 3000 tweets in de test set steken.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = dataset.airline_sentiment.values\n",
    "features = dataset.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=3000, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(text, language = 'english', min_word_size = 2):\n",
    "    # remove html\n",
    "    text_no_html = BeautifulSoup(str(text),\"html.parser\" ).get_text()\n",
    "    \n",
    "    # remove non-letters\n",
    "    text_alpha_chars = re.sub(\"[^a-zA-Z']\", \" \", str(text_no_html)) \n",
    "        \n",
    "    # convert to lower-case\n",
    "    text_lower = text_alpha_chars.lower()\n",
    "    \n",
    "    # remove stop words\n",
    "    stops = set(stopwords.words(language)) \n",
    "    text_no_stop_words = ' '\n",
    "    \n",
    "    for w in text_lower.split():\n",
    "        if w not in stops:  \n",
    "            text_no_stop_words = text_no_stop_words + w + ' '\n",
    "      \n",
    "       # do stemming\n",
    "    text_stemmer = ' '\n",
    "    stemmer = SnowballStemmer(language)\n",
    "    for w in text_no_stop_words.split():\n",
    "        text_stemmer = text_stemmer + stemmer.stem(w) + ' '\n",
    "         \n",
    "    # remove short words\n",
    "    text_no_short_words = ' '\n",
    "    for w in text_stemmer.split(): \n",
    "        if len(w) >= min_word_size:\n",
    "            text_no_short_words = text_no_short_words + w + ' '\n",
    " \n",
    "\n",
    "    return text_no_short_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = list(map(lambda text: text_processing(text), X_train))\n",
    "X_test = list(map(lambda text: text_processing(text), X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = CountVectorizer()\n",
    "count_vector.fit(X_train)\n",
    "X_train_bag = count_vector.transform(X_train)\n",
    "X_test_bag = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer(use_idf=True)\n",
    "transformer.fit(X_train_bag)\n",
    "X_train_bag_tf = transformer.transform(X_train_bag)\n",
    "X_test_bag_tf = transformer.transform(X_test_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11640, 9463)\n",
      "(11640,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_bag_tf.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took:  0.024755456000093545\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.97      0.85      1898\n",
      "     neutral       0.70      0.32      0.44       649\n",
      "    positive       0.76      0.42      0.54       453\n",
      "\n",
      "    accuracy                           0.75      3000\n",
      "   macro avg       0.74      0.57      0.61      3000\n",
      "weighted avg       0.74      0.75      0.71      3000\n",
      "\n",
      "confussion matrix: \n",
      " [[1840   44   14]\n",
      " [ 398  206   45]\n",
      " [ 216   46  191]]\n",
      "f1 score: 0.7456666666666667\n"
     ]
    }
   ],
   "source": [
    "# Trainen van de classifiers (naive bayes, logistic regression, SVM)\n",
    "start_time = time.process_time()\n",
    "naive_baye = MultinomialNB(alpha=0.15)\n",
    "naive_baye.fit(X_train_bag_tf, y_train)\n",
    "print('Training took: ', time.process_time() - start_time)\n",
    "\n",
    "y_pred_nb = naive_baye.predict(X_test_bag_tf)\n",
    "\n",
    "print('classification report: \\n', classification_report(y_test, y_pred_nb))\n",
    "print('confussion matrix: \\n', confusion_matrix(y_test, y_pred_nb))\n",
    "print('f1 score:', metrics.f1_score(y_test, y_pred_nb, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "/home/florian/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:400: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "/home/florian/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:400: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "/home/florian/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:400: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "/home/florian/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:400: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters -> {'alpha': 0.15242747880668034}\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV #scikit-optimize\n",
    "parameters = {\n",
    "    'alpha': (0.01, 1, 'uniform')\n",
    "}\n",
    "\n",
    "bayes_search = BayesSearchCV(MultinomialNB(),parameters,n_iter=20,cv=5,verbose=1,n_jobs=-1)\n",
    "bayes_search.fit(X_train_bag_tf, y_train)\n",
    "\n",
    "print('best parameters ->', bayes_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.97      0.84      1882\n",
      "     neutral       0.72      0.33      0.45       655\n",
      "    positive       0.80      0.45      0.58       463\n",
      "\n",
      "    accuracy                           0.75      3000\n",
      "   macro avg       0.76      0.58      0.62      3000\n",
      "weighted avg       0.75      0.75      0.72      3000\n",
      "\n",
      "confussion matrix: \n",
      " [[1825   38   19]\n",
      " [ 410  213   32]\n",
      " [ 209   46  208]]\n",
      "f1 score: 0.7486666666666668\n"
     ]
    }
   ],
   "source": [
    "y_pred_bs = bayes_search.predict(X_test_bag_tf)\n",
    "\n",
    "print('classification report: \\n', classification_report(y_test, y_pred_bs))\n",
    "print('confussion matrix: \\n', confusion_matrix(y_test, y_pred_bs))\n",
    "print('f1 score:', metrics.f1_score(y_test, y_pred_bs, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florian/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:400: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:400: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took:  562.168568962\n",
      "Best parameters ->  {'C': 11.826849554711986, 'solver': 'liblinear'}\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86      1882\n",
      "     neutral       0.63      0.62      0.63       655\n",
      "    positive       0.71      0.75      0.73       463\n",
      "\n",
      "    accuracy                           0.79      3000\n",
      "   macro avg       0.74      0.74      0.74      3000\n",
      "weighted avg       0.79      0.79      0.79      3000\n",
      "\n",
      "confussion matrix: \n",
      " [[1624  175   83]\n",
      " [ 192  407   56]\n",
      " [  57   61  345]]\n",
      "f1 score: 0.792\n"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time_ns()\n",
    "log_reg = LogisticRegression(C=1, class_weight='balanced', max_iter=500)\n",
    "params = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C': (0.01, 100, 'uniform')\n",
    "}\n",
    "\n",
    "bayes_search = BayesSearchCV(log_reg,params,n_iter=50,cv=5,n_jobs=-1)\n",
    "bayes_search = bayes_search.fit(X_train_bag_tf, y_train)\n",
    "print('Training took: ', (time.process_time_ns() - start_time) * 10**-9)\n",
    "\n",
    "log_reg = bayes_search.best_estimator_\n",
    "print('Best parameters -> ', bayes_search.best_params_)\n",
    "\n",
    "y_pred_log = log_reg.predict(X_test_bag_tf)\n",
    "print('classification report: \\n', classification_report(y_test, y_pred_log))\n",
    "print('confussion matrix: \\n', confusion_matrix(y_test, y_pred_log))\n",
    "print('f1 score:', metrics.f1_score(y_test, y_pred_log, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [21888, 11640]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-226-d04d5a9b353f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlog_reg_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlog_reg_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_reg_best\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_bag_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training took: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1524\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1526\u001b[0;31m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0m\u001b[1;32m   1527\u001b[0m                          accept_large_sparse=solver != 'liblinear')\n\u001b[1;32m   1528\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    212\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [21888, 11640]"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time_ns()\n",
    "log_reg_best = LogisticRegression(C=1.20, solver='liblinear', class_weight='balanced')\n",
    "log_reg_best = log_reg_best.fit(X_train_bag_tf, y_train)\n",
    "print('Training took: ', (time.process_time_ns() - start_time) * 10**-9)\n",
    "\n",
    "y_preds = log_reg_best.predict(X_test_bag_tf)\n",
    "\n",
    "print('classification report: \\n', classification_report(y_test, y_preds))\n",
    "print('confussion matrix: \\n', confusion_matrix(y_test, y_preds))\n",
    "print('f1 score:', metrics.f1_score(y_test, y_preds, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florian/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:400: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:400: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:400: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:400: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:400: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:400: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:400: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:400: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:400: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:400: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took:  488.67318855800005\n",
      "best params ->  {'class_weight': None, 'gamma': 27.759432648447916, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time_ns()\n",
    "svmc = svm.SVC()\n",
    "params = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': (0.01, 100, 'uniform'),\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "bayes_search = BayesSearchCV(svmc,params,n_iter=50,cv=5,n_jobs=-1)\n",
    "bayes_search = bayes_search.fit(X_train_bag_tf, y_train)\n",
    "print('Training took: ', (time.process_time_ns() - start_time) * 10**-9)\n",
    "\n",
    "svmc = bayes_search.best_estimator_\n",
    "print('best params -> ', bayes_search.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.92      0.88      1882\n",
      "     neutral       0.70      0.54      0.61       655\n",
      "    positive       0.80      0.70      0.75       463\n",
      "\n",
      "    accuracy                           0.81      3000\n",
      "   macro avg       0.78      0.72      0.75      3000\n",
      "weighted avg       0.80      0.81      0.80      3000\n",
      "\n",
      "confussion matrix: \n",
      " [[1738   96   48]\n",
      " [ 268  355   32]\n",
      " [  83   55  325]]\n",
      "f1 score: 0.806\n"
     ]
    }
   ],
   "source": [
    "y_preds = svmc.predict(X_test_bag_tf)\n",
    "\n",
    "print('classification report: \\n', classification_report(y_test, y_preds))\n",
    "print('confussion matrix: \\n', confusion_matrix(y_test, y_preds))\n",
    "print('f1 score:', metrics.f1_score(y_test, y_preds, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took:  7.310985469\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.92      0.88      1882\n",
      "     neutral       0.70      0.54      0.61       655\n",
      "    positive       0.80      0.70      0.75       463\n",
      "\n",
      "    accuracy                           0.81      3000\n",
      "   macro avg       0.78      0.72      0.75      3000\n",
      "weighted avg       0.80      0.81      0.80      3000\n",
      "\n",
      "confussion matrix: \n",
      " [[1738   96   48]\n",
      " [ 268  355   32]\n",
      " [  83   55  325]]\n",
      "f1 score: 0.806\n"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time_ns()\n",
    "svmc_best = svm.SVC(kernel='linear')\n",
    "svmc_best = svmc_best.fit(X_train_bag_tf, y_train)\n",
    "print('Training took: ', (time.process_time_ns() - start_time) * 10**-9)\n",
    "\n",
    "y_preds = svmc_best.predict(X_test_bag_tf)\n",
    "\n",
    "print('classification report: \\n', classification_report(y_test, y_preds))\n",
    "print('confussion matrix: \\n', confusion_matrix(y_test, y_preds))\n",
    "print('f1 score:', metrics.f1_score(y_test, y_preds, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welke classifier heeft jouw voorkeur? Beargumenteer in termen van accuracy, f1-score maar ook de berekeningstijd.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antwoord\n",
    "\n",
    "Alle classifiers hebben last van de ongebalanceerde data.  \n",
    "**Naive Bayes** traint het snelst, maar behaald ook de laagste F1-scores (74%). Die heeft voornamelijk moeite met **recall** van de verschillende klasses.  \n",
    "**Logistic Regression** traint net iets trager dan Naive Bayes, maar traint nog steeds zeer snel. Dit model behaalt ook de beste F1-score(80.8%).  \n",
    "**SVM** traint het traagst van allemaal, maar behaalt ook een goede F1-score (80.6%).  \n",
    "\n",
    "Mijn voorkeur gaat naar **Logistic Regression**. Dit model traint zeer snel en behaalt de beste F1-score. De recall van dit model ligt ook hoger dan dat van **SVM** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeloptimalisatie\n",
    "\n",
    "- Stel dat de airlines vooral geÃ¯nteresseerd zijn in het correct opsporen van negatieve tweets. Welke aanpassingen zou je kunnen doen om ervoor te zorgen dat het model minder negatieve tweets verkeerd classificeert? Test deze aanpassingen.\n",
    "\n",
    "- Bekom je een beter model met een hogere accuraatheid wanneer je ook de feature airline in rekening brengt? Een optie hierbij is ook om voor elke airline een apart model te trainen. \n",
    "\n",
    "- Bekom je een beter model wanneer je de lengte van de tweets in rekening brengt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeloptimalisatie\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=5)\n",
    "X_train_bag_tf, y_train = sm.fit_resample(X_train_bag_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took:  0.210001402\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86      1882\n",
      "     neutral       0.60      0.69      0.64       655\n",
      "    positive       0.71      0.77      0.74       463\n",
      "\n",
      "    accuracy                           0.79      3000\n",
      "   macro avg       0.74      0.76      0.75      3000\n",
      "weighted avg       0.80      0.79      0.79      3000\n",
      "\n",
      "confussion matrix: \n",
      " [[1558  237   87]\n",
      " [ 147  453   55]\n",
      " [  45   63  355]]\n",
      "f1 score: 0.7886666666666666\n"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time_ns()\n",
    "log_reg_best = LogisticRegression(C=1.2, solver='liblinear')\n",
    "log_reg_best = log_reg_best.fit(X_train_bag_tf, y_train)\n",
    "print('Training took: ', (time.process_time_ns() - start_time) * 10**-9)\n",
    "\n",
    "y_preds = log_reg_best.predict(X_test_bag_tf)\n",
    "\n",
    "print('classification report: \\n', classification_report(y_test, y_preds))\n",
    "print('confussion matrix: \\n', confusion_matrix(y_test, y_preds))\n",
    "print('f1 score:', metrics.f1_score(y_test, y_preds, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dataset.text\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, random_state=123, test_size=3000)\n",
    "\n",
    "X_train = X_train.apply(text_processing)\n",
    "X_test= X_test.apply(text_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confussion_matrix \n",
      " [[1757   80   45]\n",
      " [ 272  354   29]\n",
      " [  86   56  321]]\n",
      "report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.93      0.88      1882\n",
      "     neutral       0.72      0.54      0.62       655\n",
      "    positive       0.81      0.69      0.75       463\n",
      "\n",
      "    accuracy                           0.81      3000\n",
      "   macro avg       0.79      0.72      0.75      3000\n",
      "weighted avg       0.80      0.81      0.80      3000\n",
      "\n",
      "f1 0.8106666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florian/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def get_airline(value):\n",
    "    idx = value.index\n",
    "    airlines = []\n",
    "    for i in idx:\n",
    "        airlines.append(dataset['airline'].iloc[i])\n",
    "    tmp_dataframe = pd.DataFrame(data={'airline': airlines})\n",
    "    tmp_dataframe = pd.get_dummies(data=tmp_dataframe)\n",
    "    return tmp_dataframe\n",
    "\n",
    "params = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C': (0.01, 100, 'uniform')\n",
    "}\n",
    "\n",
    "# params = {\n",
    "#     'alpha': (0.1, 100, 'uniform')\n",
    "# }\n",
    "\n",
    "# params = {\n",
    "#     'kernel': ['linear', 'rbf'],\n",
    "#     'gamma': (0.01, 100, 'uniform'),\n",
    "#     'class_weight': ['balanced', None]\n",
    "# }\n",
    "\n",
    "classifier = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('text', Pipeline([\n",
    "            ('vectorizer', CountVectorizer()),\n",
    "            ('tdif', TfidfTransformer(use_idf=True))\n",
    "        ])),\n",
    "        ('airline', Pipeline([\n",
    "            ('count', FunctionTransformer(get_airline, validate=False))\n",
    "        ]))\n",
    "    ])),\n",
    "    ('Logistic', BayesSearchCV(LogisticRegression(), params, scoring='f1_micro', cv=3, n_iter=20))\n",
    "])\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_preds = classifier.predict(X_test)\n",
    "\n",
    "print('confussion_matrix \\n', confusion_matrix(y_test, y_preds))\n",
    "print('report \\n', classification_report(y_test, y_preds))\n",
    "print('f1', metrics.f1_score(y_test, y_preds, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.2287449885329151, 'solver': 'saga'}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier['Logistic'].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cyber trolls\n",
    "\n",
    "Een cyber troll heeft als bedoeling emotionele reacties uit te lokken door opzettelijk verkeerde, kwetsende en agressieve berichten te plaatsen op forums, newsgroups, social media, etc. Online platformen hebben er een groot belang bij om deze cyber trolls te kunnen detecteren en weren van hun platform. Daarvoor gebruiken ze geavanceerde nlp algoritmes. Ontwerp zelf een cyber troll detector op basis. Je kan daarvoor beroep doen op de dataset 'Cybetrolls.csv'. Om de dataset te evalueren gebruik je een test set van 5000 berichten.\n",
    "\n",
    "Welke woorden worden het meest door cyber trolls gebruikt? Geef een top 10.\n",
    "\n",
    "Voor het evalueren van de classifier gebruik je de volgende metrics: accuracy, f1 score en de ROC. Formuleer conclusies. Bijvoorbeeld naar de keuze toe van de classifier, interpretatie van de ROC of auROC. Toon enkele verkeerd geclassificeerde berichten en probeer te achterhalen waarom ze verkeerd geclassificeerd werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Get fucking real dude.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>She is as dirty as they come  and that crook Rengel  the Dems are so fucking corrupt it's a joke. Make Republicans look like  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>why did you fuck it up. I could do it all day too. Let's do it when you have an hour. Ping me later to sched writing a book here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Dude they dont finish enclosing the fucking showers. I hate half assed jobs. Whats the reasononing behind it? Makes no sense.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>WTF are you talking about Men? No men thats not a menage  that's just gay.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annotation  \\\n",
       "0           1   \n",
       "1           1   \n",
       "2           1   \n",
       "3           1   \n",
       "4           1   \n",
       "\n",
       "                                                                                                                              content  \n",
       "0                                                                                                              Get fucking real dude.  \n",
       "1   She is as dirty as they come  and that crook Rengel  the Dems are so fucking corrupt it's a joke. Make Republicans look like  ...  \n",
       "2   why did you fuck it up. I could do it all day too. Let's do it when you have an hour. Ping me later to sched writing a book here.  \n",
       "3       Dude they dont finish enclosing the fucking showers. I hate half assed jobs. Whats the reasononing behind it? Makes no sense.  \n",
       "4                                                          WTF are you talking about Men? No men thats not a menage  that's just gay.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Cybetrolls.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
